# Preparing data tables for TOPMed data

## Setup

```{r}
library(AnVIL)
library(dplyr)
library(readr)
library(stringr)
library(jsonlite)
```

### Set constants

```{r}
# These are the standard values used by dbGaP, but they can be overridden here.
SUBJECT_FILE_PATTERN <- "Subject.MULTI.txt.gz"
SAMPLE_FILE_PATTERN <- "Sample.MULTI.txt.gz"
ATTRIBUTES_FILE_PATTERN <- "Sample_Attributes.*txt.gz"

# Could probably figure some of these out from the xml.
SUBJECT_COLUMN <- "SUBJECT_ID"
CONSENT_COLUMN <- "CONSENT"
SEX_COLUMN <- "SEX"
SAMPLE_COLUMN <- "SAMPLE_ID"
BODY_SITE_COLUMN = "BODY_SITE"
PHASE_COLUMN <- "TOPMed_Phase"
PROJECT_COLUMN <- "TOPMed_Project"
FUNDING_COLUMN <- "Funding_Source"
SEQUENCING_COLUMN <- "SEQUENCING_CENTER"

TISSUE_SOURCE <- "UBERON:0000178" # UBERON code for whole blood
```

### Get information about the current workspace

```{r}
BUCKET <- avbucket()
```

### Get information about the study

```{r}
proj <- avtable("project")
(phs <- substr(proj$`pfb:dbgap_accession_number`,1,9))
str <- str_split_1(proj$`pfb:project_name`, "_")
(study_nickname = str[1])
(consent_abbreviation <- str[2])
```

## Find and read subject and sample files

```{r}
files <- avfiles_ls(path=file.path("uploaded_data_cc"), full_names=TRUE)
length(files)
```

### Subject file

```{r}
subj_file <- files[str_detect(files, SUBJECT_FILE_PATTERN)]
stopifnot(length(subj_file) == 1)
subj_file
```

```{r}
fl <- tempfile()
gsutil_cp(file.path(BUCKET, subj_file), fl)
subj <- read_tsv(fl, col_types=cols(.default=col_character()), comment="#")
head(subj)
```


### Sample file

```{r}
samp_file <- files[str_detect(files, SAMPLE_FILE_PATTERN)]
stopifnot(length(samp_file) == 1)
samp_file
```

```{r}
fl <- tempfile()
gsutil_cp(file.path(BUCKET, samp_file), fl)
samp <- read_tsv(fl, col_types=cols(.default=col_character()), comment="#")
head(samp)
```

### Sample attributes file

```{r}
attr_file <- files[str_detect(files, ATTRIBUTES_FILE_PATTERN)]
stopifnot(length(attr_file) == 1)
attr_file
```

```{r}
fl <- tempfile()
gsutil_cp(file.path(BUCKET, attr_file), fl)
attr <- read_tsv(fl, col_types=cols(.default=col_character()), comment="#")
head(attr)
```

The above files may contain subjects and samples not in the current VCF files (exchange-area only samples).
Get the freeze 9 genetic sex file for a list of included samples.

```{r}
txt_files <- avtable("reference_file") %>%
  filter(`pfb:data_format` == "TXT", grepl("TOPMed_WGS_genetic_sex.txt$", `pfb:file_name`)) %>%
  select(`pfb:ga4gh_drs_uri`) %>%
  unlist(use.names = FALSE)
```

```{r}
fl <- tempfile()
system("pip install --upgrade --no-cache-dir terra-notebook-utils")
tnu <- "/usr/local/bin/tnu"
system(paste(tnu, "config set-workspace", avworkspace()))
system(paste(tnu, "config set-workspace-namespace", avworkspace_namespace()))
system(paste(tnu, "drs copy-batch", paste(txt_files, collapse=" "), "--dst", fl))
f9samp <- read_tsv(fl, col_types=cols(.default=col_character()))$SAMPLE_ID
length(f9samp)
```


## Create tables for PRIMED data model

### Sample table

```{r}
dat <- attr %>%
  left_join(samp) %>%
  filter(!!sym(SAMPLE_COLUMN) %in% f9samp)
```

```{r}
count(dat, !!sym(BODY_SITE_COLUMN))
```

```{r}
count(dat, !!sym(PHASE_COLUMN), !!sym(PROJECT_COLUMN), !!sym(FUNDING_COLUMN), !!sym(SEQUENCING_COLUMN))
```

```{r}
sample_table <- dat %>%
  mutate(SEQUENCING_CENTER = sub(" ", "_", !!sym(SEQUENCING_COLUMN))) %>%
  mutate(batch = ifelse(!is.na(!!sym(PHASE_COLUMN)),
                        paste0(SEQUENCING_CENTER, "_Phase", !!sym(PHASE_COLUMN)),
                        paste0(SEQUENCING_CENTER, "_", !!sym(FUNDING_COLUMN)))) %>%
  mutate(batch = sub("Phaselegacy", "legacy", batch)) %>%
  select(sample_id = !!sym(SAMPLE_COLUMN),
         subject_id = !!sym(SUBJECT_COLUMN),
         dbgap_sample_id = dbGaP_Sample_ID,
         batch) %>%
  mutate(tissue_source = TISSUE_SOURCE)
```

```{r}
count(sample_table, batch)
```

### Sample set table

```{r}
sample_set <- dat %>%
  select(sample_id = !!sym(SAMPLE_COLUMN)) %>%
  mutate(sample_set_id = paste("topmed", "freeze9", study_nickname, consent_abbreviation, sep="_"))
```


### Subject table

```{r}
# expect 1=male, 2=female
# does not account for other values, so check
map_sex <- function(x) {
  print(table(x, useNA="ifany"))
  sex <- c("1"="Male", "2"="Female")[x]
  sex[is.na(sex)] <- "Unknown"
  return(sex)
}
```

```{r}
subject_table <- subj %>%
  filter(!!sym(SUBJECT_COLUMN) %in% dat[[SUBJECT_COLUMN]]) %>%
  rename(
    subject_id=!!sym(SUBJECT_COLUMN),
    dbgap_subject_id=dbGaP_Subject_ID,
  ) %>%
  mutate(
    consent_code=consent_abbreviation,
    study_nickname=study_nickname,
    dbgap_submission=TRUE,
    dbgap_study_id=phs,
    reported_sex=map_sex(!!sym(SEX_COLUMN))
  ) %>%
  select(
    subject_id,
    dbgap_subject_id,
    consent_code,
    study_nickname,
    dbgap_submission,
    dbgap_study_id,
    reported_sex
  )
```

### Dataset table

```{r}
fields <- list(
  sample_set_id = paste("topmed", "freeze9", study_nickname, consent_abbreviation, sep="_"),
  seq_center = paste(sort(unique(dat[[SEQUENCING_COLUMN]])), collapse=" | "),
  reference_assembly = "GRCh38",
  alignment_method = "BWA-MEM",
  sequencing_assay = "WGS",
  seq_platform = "Illumina HiSeq X"
)
dataset_table <- tibble(field=names(fields),
                        value=unlist(fields))
```

### File table

```{r}
chr_from_filename <- function(f) {
  chr <- stringr::str_extract(f, "chr[:alnum:]+[:punct:]")
  chr <- sub("chr", "", chr, fixed=TRUE)
  chr <- sub(".", "", chr, fixed=TRUE)
  return(chr)
}

file_table_1 <- avtable("reference_file") %>%
  filter(`pfb:data_format` == "VCF") %>%
  mutate(chromosome = chr_from_filename(`pfb:file_name`)) %>%
  select(file_path = `pfb:ga4gh_drs_uri`,
         file_name = `pfb:file_name`,
         file_type = `pfb:data_format`,
         md5sum = `pfb:md5sum`,
         chromosome)
```

```{r}
file_table_2 <- avtable("reference_file") %>%
  filter(`pfb:data_format` == "TXT", grepl("TOPMed_WGS", `pfb:file_name`)) %>%
  select(file_path = `pfb:ga4gh_drs_uri`,
         file_name = `pfb:file_name`,
         md5sum = `pfb:md5sum`) %>%
  mutate(file_type = ifelse(grepl("_DD.txt$", file_name), "data dictionary", 
                     ifelse(grepl("kinship", file_name), "supporting file",
                            "quality metrics"))) %>%
  mutate(chromosome = "None")

file_table <- bind_rows(file_table_1, file_table_2)
```


## Write tables to google bucket

```{r}
tables <- list("subject"=subject_table, "sample"=sample_table, "sample_set"=sample_set, 
               "sequencing_dataset"=dataset_table, "sequencing_file"=file_table)
file_list <- list()
for (t in names(tables)) {
  outfile <- paste0(t, "_table.tsv")
  write_tsv(tables[[t]], outfile)
  bucketfile <- paste0(BUCKET, "/data_tables/", outfile)
  gsutil_cp(outfile, bucketfile)
  file_list[[t]] <- bucketfile
}
```

## Workflow inputs

```{r}
json <- list("validate_genotype_model.table_files" = file_list,
             "validate_genotype_model.model_url" = "https://raw.githubusercontent.com/UW-GAC/primed_data_models/main/PRIMED_genotype_data_model.json",
             "validate_genotype_model.workspace_name" = avworkspace_name(),
             "validate_genotype_model.workspace_namespace" = avworkspace_namespace(),
             "validate_genotype_model.import_tables" = "true",
             "validate_genotype_model.md5check.project_id" = gcloud_project()
) %>% toJSON(pretty=TRUE, auto_unbox=TRUE, unbox=TRUE)
write(json, "validate_genotype_model.json")
```

Check if we need to request a larger instance to check the VCF files
(default is 10G)

```{r}
file_size_bytes <- avtable("reference_file") %>%
  filter(`pfb:data_format` == "VCF") %>%
  select(`pfb:file_size`) %>%
  unlist() %>%
  max()
(file_size_gb <- file_size_bytes / 1e9)
```

