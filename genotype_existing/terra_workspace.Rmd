---
title: "PRIMED example notebook: import from Terra"
output: html_notebook
---

# Import data to workspace: Terra example

In this notebook we will prepare 1000 Genomes data for importing into data tables, using the Bioconductor AnVIL package to interact with the workspace.

## Install and load R packages

```{r}
# get the latest version of AnVIL from github
#remotes::install_github("Bioconductor/AnVIL", dependencies=FALSE)
#remotes::install_github("UW-GAC/AnvilDataModels")
library(AnVIL)
library(AnvilDataModels)
library(tidyverse)
```

## Source data

We are going to import data from another (open-access) AnVIL workspace.

First, we look at the data tables:

```{r}
avtables(namespace="amp-t2d-op", name="2019_ASHG_Reproducible_GWAS-V2")
```

We import the "sample" table as a tibble:

```{r}
sample <- avtable("sample", namespace="amp-t2d-op", name="2019_ASHG_Reproducible_GWAS-V2")
head(sample)
```

## Prepare tables according to data model

### Sample and subject tables

All phenotypes were simulated for the purposes of the GWAS tutorial in the origin workspace. In PRIMED (as in dbGaP and other AnVIL consortia) we distinguish between subjects (participants in a study) and samples (e.g. blood sample for genotyping). Multiple samples may be associated with the same subject. All of the data in this table more appropriately belongs in the subject table. In the PRIMED data model, we will actually have multiple tables, with the subject table containing key information like study and consent, and separate phenotype tables for each phenotype domain.

```{r}
subject <- sample %>%
  rename(subject_id=sample_id, 
         superpopuation=ancestry)
head(subject)
```

The sample table links samples to subjects. For this 1000 Genomes example, sample_id and subject_id have the same values, but using different identifiers is recommended.

```{r}
sample <- sample %>%
  select(sample_id) %>%
  mutate(subject_id=sample_id)
head(sample)
```

### Sample sets

Sample sets define groups of samples and link them to datasets. We will create one set with all samples.

```{r}
sample_set <- create_set_all(sample, table_name="sample")
head(sample_set)
```

### Datasets

Each dataset is linked to a sample set. Each type of dataset (array, imputation, sequencing) has its own type-specific columns, which should be saved as a set of field/value pairs. In this case, we have sequencing data.

```{r}
sequencing_fields <- list(
  sample_set_id = "all",
  reference_assembly = "GRCh37",
  sequencing_assay = "WGS",
  seq_platform = "Illumina"
)
sequencing_dataset <- tibble(field=names(sequencing_fields),
                             value=unlist(sequencing_fields))
```


Files are linked to datasets. Rather than copying data, we create a 'sequencing_file' table that references VCF files in their origin workspace.
In the source workspace, the paths to the VCF files are stored in a "Workspace data" table.

```{r}
avdata(namespace="amp-t2d-op", name="2019_ASHG_Reproducible_GWAS-V2")
```

```{r}
vcf <- avdata(namespace="amp-t2d-op", name="2019_ASHG_Reproducible_GWAS-V2") %>%
  filter(key == "vcf_files") %>%
  select(value) %>%
  unlist()
head(vcf)
```

The file paths are in a comma-delimited string, so we extract them into a vector.

```{r}
vf <- strsplit(vcf, split='\",\"', fixed=TRUE) %>%
  unlist(use.names=FALSE)

vf <- sub('[\"', '', vf, fixed=TRUE)
vf <- sub('\"]', '', vf, fixed=TRUE)

vf
```

The primary key of the 'file' table in the PRIMED data model is the md5 hash. As this is not provided by the source workspace, we compute it. We use 'gsutil_pipe' from the AnVIL package to open a connection to the file without copying it to the local instance.

```{r}
md5 <- sapply(vf, function(f) {
  gsutil_pipe(f, "rb") %>%
    openssl::md5() %>%
    as.character()
}, USE.NAMES=FALSE)

```



Extract chromosome from the file name to add to the table.

```{r}
chr <- stringr::str_extract(vf, "chr[:alnum:]+[:punct:]")
chr <- sub("chr", "", chr, fixed=TRUE)
chr <- sub(".", "", chr, fixed=TRUE)
```

```{r}
sequencing_file <- tibble(md5sum = md5,
                          chromosome = chr, 
                          file_path = vf,
                          file_type = "VCF")
```


## Write tables as files to workspace bucket

To check the tables using a workflow, they must be written as files to the workspace bucket.

```{r}
bucket <- avbucket()

table_names <- c("subject", "sample", "sample_set", "sequencing_dataset", "sequencing_file")
for (t in table_names) {
  outfile <- paste0("1000G_", t, "_table.tsv")
  write_tsv(get(t), outfile)
  gsutil_cp(outfile, bucket)
}
```

## Check tables against data model

Once all tables have been created, we can check that they conform to the data model. This is most easily accomplished by providing the paths to the tables in TSV format as input to the `genotype_report` workflow.
